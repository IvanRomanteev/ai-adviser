# ----------------------------------------------------------------------------
# Banking Orchestrator ADK Agent configuration
#
# Copy this file to `.env` and fill in the appropriate values before running
# the agent.  The agent uses LiteLLM to connect to Azure OpenAI / Foundry
# deployments and calls your existing RAG service for knowledge-based queries.
# ----------------------------------------------------------------------------

# Azure LLM configuration
# Set this to ``azure/<your-deployment-name>`` to instruct LiteLLM to call
# Azure endpoints.  Alternatively leave unset and specify ``CHAT_DEPLOYMENT``
# to derive the model name automatically.
ORCH_MODEL=azure/<your-deployment-name>

# The base URL of your Azure OpenAI resource (without trailing slash), e.g.
# https://gpt-oss-120b.openai.azure.com  (do not include /openai/deployments)
AZURE_API_BASE=https://<your-ai-resource>.openai.azure.com

# The API version for Azure OpenAI.  The default version should match
# your deployment (e.g. 2024-10-21 for Foundry models).
AZURE_API_VERSION=2024-10-21

# API key for your Azure OpenAI resource
AZURE_API_KEY=<your-secret-key>

# Base URL for the RAG service.  The banking RAG chat tool will POST to
# ``${RAG_BASE_URL}/rag_chat``.  If running the FastAPI app locally use
# http://localhost:8000.
RAG_BASE_URL=http://localhost:8000

# Directory where user memory files are stored.  The orchestrator will
# persist conversation history and summaries under this location.  Create
# this directory if it does not exist.
MEMORY_STORE_PATH=.memory

# Citation enforcement flags forwarded to the RAG service.  These must be
# consistent with the configuration of your FastAPI app to ensure the
# assistant produces properly cited answers.  It is recommended to set
# both of these to true.
CITATION_ENFORCE_STRUCTURE=true
CITATION_STRICT=true